version: '3.8'

services:
  nats_local:
    image: nats:2.9.19
    ports:
      - "4222:4222"
      - "8088:8088"
      - "6222:6222"
    command: "-js -c /nats/nats.conf --name nats_local -p 4222"
    # command: "-js"
    volumes:
      - ./services/nats/nats.conf:/nats/nats.conf
      - nats_data1:/data

  rasa:
    restart: always
    container_name: rasa-container
    image: rasa/rasa:3.6.6-full
    ports:
      - "5005:5005"
    volumes:
      - ./generated/rasa:/app
      - ./generated/models:/models
    env_file:
      - .env
    command: run --enable-api --cors "*" --debug -m /models/${RASA_MODEL}
    #command: run --help

  duckling:
    restart: always
    container_name: duckling
    image: rasa/duckling
    ports:
      - "8000:8000"

  action_server:
    restart: always
    container_name: actionServer
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "5055:5055"
    volumes:
      - ./client:/app/client
      - ./src:/app/src
      - ./common:/app/common

  tortise_cache:
    restart: always
    container_name: tortiseCache
    build:
      context: .
      dockerfile: Dockerfile.tortiseCache
    volumes:
      - ./cache:/app/cache
      - ./src:/app/src
      - ./common:/app/common
  webapp:
    restart: always
    container_name: webapp
    build:
      context: ./services/webapp
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    volumes:
      - ./services/webapp/:/app

  stt:
    environment:
      - CUDA_LAUNCH_BLOCKING=1
    build:
      context: ./services/stt
      dockerfile: Dockerfile
    volumes:
      - /data/voice:/data/voice
      - /data/ai-voice-cloning:/data/ai-voice-cloning
      - ~/.cache:/root/.cache/
      - ~/.ssh:/root/.ssh
    deploy:
      # mode: replicated
      # replicas: 4
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]

  tts-piper:
    restart: always
    container_name: tts-piper
    build:
      context: ./services/tts_piper
      dockerfile: Dockerfile

  # tts-tortise:
  #   environment:
  #     - CUDA_LAUNCH_BLOCKING=1
  #     - PYTORCH_CUDA_ALLOC_CONF=backend:native
  #   build:
  #     context: ./services/ai-voice-cloning
  #     dockerfile: Dockerfile
  #   volumes:
  #     - /data/voice:/data/voice
  #     - /data/ai-voice-cloning:/data/ai-voice-cloning
  #     - ~/.cache:/root/.cache/
  #     - ~/.ssh:/root/.ssh
  #     - ./services/ai-voice-cloning:/home/user/ai-voice-cloning
  #   ports:
  #     - "7680:7680"
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [ gpu ]


  # rvc:
  #   environment:
  #     - CUDA_LAUNCH_BLOCKING=1
  #     - PYTORCH_CUDA_ALLOC_CONF=backend:native
  #   build:
  #     context: ./services/Retrieval-based-Voice-Conversion-WebUI
  #     dockerfile: Dockerfile
  #   volumes:
  #     - /data/voice:/data/voice
  #     - ~/.cache:/root/.cache/
  #     - ~/.ssh:/root/.ssh
  #     - ./services/Retrieval-based-Voice-Conversion-WebUI/weights:/app/weights
  #     - ./services/Retrieval-based-Voice-Conversion-WebUI/opt:/app/opt
  #     - ./services/Retrieval-based-Voice-Conversion-WebUI/logs:/app/logs
  #   ports:
  #     - "7865:7865"
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [ gpu ]


volumes:
  nats_data1:
