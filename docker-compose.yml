version: '3.8'

services:
  nats_local:
    image: nats:2.9.19
    ports:
      - "4222:4222"
      - "8088:8088"
      - "6222:6222"
    command: "-js -c /nats/nats.conf --name nats_local -p 4222"
    # command: "-js"
    volumes:
      - ./services/nats/nats.conf:/nats/nats.conf
      - nats_data1:/data

  rasa:
    restart: always
    container_name: rasa-container
    image: rasa/rasa:3.6.4-full
    ports:
      - "5005:5005"
    volumes:
      - ./generated/rasa:/app
      - ./generated/models:/models
    env_file:
      - .env
    command: run --enable-api --cors "*" --debug -m /models/${RASA_MODEL}
    #command: run --help

  action_server:
    restart: always
    container_name: actionServer
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "5055:5055"
    volumes:
      - ./client:/app/client
      - ./src:/app/src
      - ./common:/app/common
  webapp:
    restart: always
    container_name: webapp
    build:
      context: ./services/webapp
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    volumes:
      - ./services/webapp/:/app

  stt:
    environment:
      - CUDA_LAUNCH_BLOCKING=1
    build:
      context: ./services/stt
      dockerfile: Dockerfile
    volumes:
      - /data/voice:/data/voice
      - /data/ai-voice-cloning:/data/ai-voice-cloning
      - ~/.cache:/root/.cache/
      - ~/.ssh:/root/.ssh
    deploy:
      # mode: replicated
      # replicas: 4
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]

  # tts-piper:
  #   restart: always
  #   container_name: tts-piper
  #   build:
  #     context: ./services/tts_piper
  #     dockerfile: Dockerfile

  tts-tortise:
    environment:
      - CUDA_LAUNCH_BLOCKING=1
      - PYTORCH_CUDA_ALLOC_CONF=backend:native
    build:
      context: ./services/ai-voice-cloning
      dockerfile: Dockerfile
    volumes:
      - /data/voice:/data/voice
      - /data/ai-voice-cloning:/data/ai-voice-cloning
      - ~/.cache:/root/.cache/
      - ~/.ssh:/root/.ssh
      - ./services/ai-voice-cloning:/home/user/ai-voice-cloning
    ports:
      - "7680:7680"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]

volumes:
  nats_data1:
